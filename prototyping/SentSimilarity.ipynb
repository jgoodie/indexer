{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fa6c9c1-dd2c-40a2-8413-c6687f8346f7",
   "metadata": {},
   "source": [
    "# BERT For Measuring Text Similarity\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/bert-for-measuring-text-similarity-eec91c6bf9e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e0c81-8b24-4203-8d93-7cbfc14a3c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a314116-a024-45f5-801f-99db4430b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Three years later, the coffin was still full of Jello.\",\n",
    "    \"The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go.\",\n",
    "    \"The person box was packed with jelly many dozens of months later.\",\n",
    "    \"He found a leprechaun in his walnut shell.\"\n",
    "]\n",
    "\n",
    "themes = ['fish', 'dream', 'toilet', 'friend']\n",
    "corpus = [\" \".join(themes)] + sentences\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "sentence_embeddings = model.encode(corpus)\n",
    "\n",
    "cs = cosine_similarity(\n",
    "    [sentence_embeddings[0]],\n",
    "    sentence_embeddings[1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c466cfd-7c96-49f8-9c19-29e60c208dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "asort = np.argsort(cs)+1\n",
    "asort[0][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7d880e-18c7-4de9-9c92-7389267be06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a3f2e-1ccf-4291-96ca-af712446edc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31bcc296-3ee4-4cef-b764-7276f1f78937",
   "metadata": {},
   "source": [
    "# MR testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce5baf7-f4e0-4130-b9f4-ef94e24d507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21bf9720-75a0-4b8c-9c43-0c7f71f3062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf0afbd-51cf-4918-8531-0e3a6a8b801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpi = glob(\"./corpus*txt\")\n",
    "# with open(corpi[1], 'r') as file:\n",
    "#         f = json.load(file)\n",
    "#         themes = [v['name'] for k, v in f[0].items()]\n",
    "#         corpus = f[1:]\n",
    "\n",
    "# for c in corpus:\n",
    "#     guid = c['guid']\n",
    "#     content = c['content']\n",
    "#     for t in themes:\n",
    "#         tc = [t] + content\n",
    "#         model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "#         sentence_embeddings = model.encode(tc)\n",
    "#         sims = cosine_similarity([sentence_embeddings[0]],sentence_embeddings[1:])[0]\n",
    "#         asort = np.argsort(cs)+1\n",
    "#         asort = asort[0][::-1]\n",
    "#         for x in asort[:5]:\n",
    "#             print(f\"{t.upper()}:\")\n",
    "#             print(f\"{tc[x]}\")\n",
    "#             #print(f\"{t.upper()}: {tc[x]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b42d611-6d0e-4b2f-aff9-f7fb9bd198b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77a53365-f608-47c1-aac8-4caf4beaedaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THEMES: big data chris9ne z data center data lake data management et cetera point of view public cloud use cases\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "A typical  example, a uAlity company; collecAng data the whole IOT big data story.\n",
      "\n",
      "Right here  we're actually talking about taking enterprise funcAonality like the storage  system or the NAS system and bring that into the cloud.\n",
      "\n",
      "One thing we believe that customers are interested in adopAng is the  preservaAon of the enterprise style of IT management while borrowing  resources and services from the cloud.\n",
      "\n",
      "I  you are spinning oﬀ a media and you want some VSP capability, do it in  the cloud and when you see it actually takes oﬀ, and the load is increasing,  move it on Prim and move it even into the enterprise environment where  you have all the stuﬀ ...\n",
      "\n",
      "You have just made the SAP HANA a cloud business which is having  a self service, orchestration, automation, charge-back model and reporting  capabilities.”  (2) Comments on HCI Type 2*  Use cases  2   “The key missing piece (for Type 2) is that, like in storage, how you have an  auto tiering mechanism, you need to have a singular mechanism in place looking  at the application workload which has just got migrated and fulfill the  requirements of that application.”  *  Type 1: HCI architecture which Integrating storage and compute functions into a single  1 node.\n",
      "\n",
      "Type two is hyper-converge storage, and we'd like  to discuss this from the following slides and of course depending on workloads,  some workloads can run on public cloud.\n",
      "\n",
      "April 13th, 2016   IT Box Co GLOBAL INFORMATION SOLUTIONS DIVISION  Hyper Converged  Version 1.0  You see a lot of that, but I think that as part of the growing pace in cloud and  just to be transparent I'm a cloud person as well.\n",
      "\n",
      "April 13th, 2016   IT Box Co GLOBAL INFORMATION SOLUTIONS DIVISION  Hyper Converged  Version 1.0  [00:48:00]  Cris: My perspecHve, going out and speaking to customers, a lot of them will look at  public cloud ﬁrst, and the percepHon the people Amazon and stuﬀ are more  focused.\n",
      "\n",
      "Cris: Cris: I think if you are selling to cloud service provider NFVs, then you'll need both of  those.\n",
      "\n",
      "When I look at this slide, this very high level  conceptually, in our market, I'd quesHon is public cloud at the top.\n",
      "\n",
      "Especially for the data stored in the public cloud, is gekng bigger.\n",
      "\n",
      "I mean, in this slide picture and the kind of the customer, you have a  mission cri@cal workload like a CRM and a ERP, something like that and also you  know that the DevOps or a big data analy@cs, start with a public cloud or  commodity hardware [00:55:41].\n",
      "\n",
      "I would like to ask you, do you know some this kind of a case, of  [migra@ng 00:20:31] this public cloud to the companies or vice versa?\n",
      "\n",
      "One thing we see in the public cloud, speciﬁcally in the Microsod public cloud  system, is the concept of telemetry, so everything you do in public cloud is going  back to Microsod.\n",
      "\n",
      "That underlying infrastructure in whatever form it is, are you ﬁnding businesses  are more [inaudible 01:03:43] going to public cloud?\n",
      "\n",
      "Maybe these other opLons, which for example is the virtualizaLon of some of  this storage of data measurement services that, you have on the premise into  the cloud.\n",
      "\n",
      "PotenLally it’s like the same cluster, it’s going to cloud aware it’s become  more capable of dealing with, cloud maybe applicaLons, as well as managing  cloud services in reachable locaLons, QOS security you’ll expect that given the  context.\n",
      "\n",
      "[01:32:00] It can enable conservaLve network layers, such as wanLng the telecom  infrastructure, to go towards open base or compute [inaudible 01:32:08] and  so on, what we should do in the enterprise.\n",
      "\n",
      "  (Comment on our use case about data lake on HCI Type2) Customer E is  building data lake.\n",
      "\n",
      "There’s a huge ecosystem being created  with tens of development packages applicaLons, open source and I cannot see  major businesses not, it becomes even more [inaudible 00:43:01].\n",
      "\n",
      "Therefore, the management framework and  the portal and everything that goes with the hyper-converge will be  consuming cloud resources and services, transparently.\n",
      "\n",
      "If you start to consume things from  the public cloud perspecIve, it's very important.\n",
      "\n",
      "Maybe where  we see a liile diﬀerent is that most of the Ime when you go cloud,  you have to adopt the management rules of the public cloud.\n",
      "\n",
      "The idea is potenIally leverage it as a data lake, build it, but also an  environment where you can have mulIple types of data  management services, so that, for example, HCP today, you know it  in its hardware form.\n",
      "\n",
      "They are interested in IT Box Co solution for big data integration with Pentaho  etc.\n",
      "\n",
      "I think also [inaudible  00:42:12] customer has the choice, such as the public cloud, it's good  for the tes9ng and development for the cost phase of the tes9ng  applica9on such as tes9ng big data on Itex or tes9ng IOT.\n",
      "\n",
      "I've got a very huge data lake,  so if we move forward, we've got not only the virtual security, but the  physical security.\n",
      "\n",
      "We are competing against the cloud because PACS (Picture  Archiving and Communication Systems) vendors and EMR system vendors are  coming in with cloud service offering to store the data.\n",
      "\n",
      "Jus9n Richards:  The startups are in the cloud?\n",
      "\n",
      "Type one is again hyper converged server and storage, which are  integra9ng storage and compute func9ons in  a single node and- I think  this merit will be the, ease and faster to deploy, ease of management,  and we think for the workload perspec9ve, simply enterprise applica9on  like VDI and email.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpi = glob(\"./corpus*txt\")\n",
    "with open(corpi[1], 'r') as file:\n",
    "        f = json.load(file)\n",
    "        themes = [v['name'] for k, v in f[0].items()]\n",
    "        corpus = f[1:]\n",
    "\n",
    "themes = \" \".join(themes)\n",
    "print(f\"THEMES: {themes}\")\n",
    "print(\"------------------------------------------------------------------------------------------------------------------\")\n",
    "print()\n",
    "\n",
    "\n",
    "for c in corpus:\n",
    "    guid = c['guid']\n",
    "    content = c['content']\n",
    "    tc = [themes] + content\n",
    "    model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "    sentence_embeddings = model.encode(tc)\n",
    "    sims = cosine_similarity([sentence_embeddings[0]],sentence_embeddings[1:])[0]\n",
    "    asort = np.argsort(sims)+1\n",
    "    asort = asort[::-1]\n",
    "    for x in asort[:5]:\n",
    "        print(f\"{tc[x]}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d986aebf-92ef-4dc7-8873-c0647a0a6e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcd6bbe-e397-4188-a89f-0a2a5ad62c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "### Critical operations for the system\n",
    "\n",
    "def sentencesims(my_themes, corpus, n=5):\n",
    "    themes = \" \".join([t for t in my_themes['themes'].keys()])\n",
    "    themes = \" \".join(set(themes.split()))\n",
    "    for c in corpus:\n",
    "        guid = c['guid']\n",
    "        content = c['content']\n",
    "        tc = [themes] + content\n",
    "        model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "        sentence_embeddings = model.encode(tc)\n",
    "        sims = cosine_similarity([sentence_embeddings[0]],sentence_embeddings[1:])[0]\n",
    "        asort = np.argsort(sims)+1\n",
    "        asort = asort[::-1]\n",
    "        for x in asort[:n]:\n",
    "            print(f\"GUID {guid}: {tc[x]}\")\n",
    "            print()\n",
    "            \n",
    "sentencesims(my_themes, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11a9919b-2139-4fb8-a92d-2cbcd77e7ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]['content'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f526d6c-9155-470a-bae8-5c06d85785ce",
   "metadata": {},
   "source": [
    "# NLPIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b6990e4d-27c6-4f95-90b8-2110864f4161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "330c0ef6-2ece-4bda-a472-9a43ff7f3be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(vec1, vec2):\n",
    "    \"\"\" Let's convert our dictionaries to lists for easier matching.\"\"\"\n",
    "    vec1 = [val for val in vec1.values()]\n",
    "    vec2 = [val for val in vec2.values()]\n",
    "    dot_prod = 0\n",
    "    for i, v in enumerate(vec1):\n",
    "        dot_prod += v * vec2[i]\n",
    "        mag_1 = np.math.sqrt(sum([x**2 for x in vec1]))\n",
    "        mag_2 = np.math.sqrt(sum([x**2 for x in vec2]))\n",
    "    return dot_prod / (mag_1 * mag_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff83d079-2333-4228-a674-d37d2b04d0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The faster Harry got to the store, the faster and faster Harry would get home.',\n",
       " 'Harry is hairy and faster than Jill.',\n",
       " 'Jill is not as hairy as Harry.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [\"The faster Harry got to the store, the faster and faster Harry would get home.\"]\n",
    "docs.append(\"Harry is hairy and faster than Jill.\")\n",
    "docs.append(\"Jill is not as hairy as Harry.\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c155efb1-3e66-4085-beab-319a24fd4e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tokens = []\n",
    "for doc in docs:\n",
    "    doc_tokens += [sorted(tokenizer.tokenize(doc.lower()))]\n",
    "all_doc_tokens = sum(doc_tokens, [])\n",
    "lexicon = sorted(set(all_doc_tokens))\n",
    "zero_vector = OrderedDict((token, 0) for token in lexicon)\n",
    "\n",
    "doc_vectors = []\n",
    "for doc in docs:\n",
    "    vec = copy.copy(zero_vector)\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    token_counts = Counter(tokens)\n",
    "    for key, value in token_counts.items():\n",
    "        vec[key] = value / len(lexicon)\n",
    "    doc_vectors.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ea339f5-e17a-4c3c-b7ca-4ec21ee2034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tfidf_vectors = []\n",
    "for doc in docs:\n",
    "    vec = copy.copy(zero_vector)\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    token_counts = Counter(tokens)\n",
    "    for key, value in token_counts.items():\n",
    "        docs_containing_key = 0\n",
    "        for _doc in docs:\n",
    "            if key in _doc:\n",
    "                docs_containing_key += 1\n",
    "        tf = value / len(lexicon)\n",
    "        if docs_containing_key:\n",
    "            idf = len(docs) / docs_containing_key\n",
    "        else:\n",
    "            idf = 0\n",
    "        vec[key] = tf*idf\n",
    "    document_tfidf_vectors.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e4e8a68-d515-474f-ab97-b551041a318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How long does it take to get to the store?\"\n",
    "query_vec = copy.copy(zero_vector)\n",
    "\n",
    "tokens = tokenizer.tokenize(query.lower())\n",
    "token_counts = Counter(tokens)\n",
    "\n",
    "for key, value in token_counts.items():\n",
    "    docs_containing_key = 0\n",
    "    for doc in docs:\n",
    "        if key in doc.lower():\n",
    "            docs_containing_key += 1\n",
    "    if docs_containing_key == 0:\n",
    "        continue\n",
    "    tf = value/len(tokens)\n",
    "    idf = len(docs)/docs_containing_key\n",
    "    query_vec[key] = tf*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54a454f0-f0c2-499e-b30f-45edcd8855da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6132857433407973"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(query_vec, document_tfidf_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73304308-32d4-4354-ad45-1ef3c17f026f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(query_vec, document_tfidf_vectors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f61bb463-3324-4a98-8b63-42e929c95b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(query_vec, document_tfidf_vectors[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4de2ba3e-c3dd-45ff-9d29-e1bae69800df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/ai%C2%B3-theory-practice-business/use-gpu-in-your-pytorch-code-676a67faed09\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\" \n",
    "\n",
    "device = torch.device(dev)\n",
    "cuda = torch.device('cuda')     # Default CUDA device\n",
    "cuda0 = torch.device('cuda:0')\n",
    "cuda1 = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c6692a65-e7f3-4319-922d-7adb5dc3f0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0218, -0.0120,  0.0751, -0.0462, -0.0030,  0.0359, -0.0107,  0.1124,\n",
       "         0.0466,  0.0317, -0.0743, -0.0534, -0.0541,  0.0668, -0.0301,  0.0067,\n",
       "        -0.0880,  0.0521,  0.1038, -0.0142, -0.1874,  0.0231, -0.0638,  0.0549,\n",
       "        -0.2302,  0.1356,  0.0156,  0.1173, -0.0147, -0.0610, -0.0421, -0.0905,\n",
       "         0.0730, -0.0375,  0.1820,  0.0050,  0.1159,  0.1038, -0.0736, -0.0991,\n",
       "        -0.0556, -0.1296, -0.0726, -0.0030, -0.0003, -0.0639, -0.0581, -0.0035,\n",
       "         0.0170,  0.0156,  0.0198,  0.1042,  0.1606, -0.1383, -0.0982, -0.0272,\n",
       "         0.0352,  0.1743,  0.1269, -0.1168,  0.0923,  0.0318,  0.0286, -0.0811,\n",
       "        -0.1772,  0.1352,  0.0039, -0.1444,  0.0541,  0.1122, -0.0457, -0.0635,\n",
       "         0.0620,  0.0261, -0.0147,  0.1097, -0.0705,  0.0329, -0.0510, -0.0074,\n",
       "        -0.1664, -0.1363, -0.0201, -0.0019, -0.0978, -0.0119,  0.0870, -0.1468,\n",
       "        -0.0423,  0.0140,  0.1048, -0.1867, -0.2359,  0.0283,  0.0401, -0.1466,\n",
       "         0.0552, -0.0212, -0.0469,  0.0237,  0.1445,  0.0006, -0.2578,  0.1310,\n",
       "         0.0314,  0.0598,  0.0564,  0.0369, -0.0742,  0.0395,  0.2006,  0.0269,\n",
       "        -0.1163, -0.0842,  0.0205, -0.0723, -0.0092,  0.0361,  0.0202,  0.0899,\n",
       "        -0.0315, -0.1534,  0.1931,  0.0073,  0.0949,  0.0283,  0.0205,  0.2068],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = torch.randn(100, 128, device=cuda1)\n",
    "input2 = torch.randn(100, 128, device=cuda1)\n",
    "cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "output = cos(input1, input2)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "24cdbffa-d41b-477b-9fac-3c3d1ce5b68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6133, device='cuda:1')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine_sim(query_vec, document_tfidf_vectors[0])\n",
    "query = torch.tensor(list(query_vec.values()), device=cuda1)\n",
    "tfidf_vec = torch.tensor(list(document_tfidf_vectors[0].values()), device=cuda1)\n",
    "cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "output = cos(query, tfidf_vec)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7c599cd0-2af5-47c7-af92-672b15abf239",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpi = glob(\"./corpus*txt\")\n",
    "with open(corpi[1], 'r') as file:\n",
    "        f = json.load(file)\n",
    "\n",
    "corpus = f[2]['content']\n",
    "\n",
    "document_tfidf_vectors = []\n",
    "for doc in corpus:\n",
    "    vec = copy.copy(zero_vector)\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    token_counts = Counter(tokens)\n",
    "    for key, value in token_counts.items():\n",
    "        docs_containing_key = 0\n",
    "        for _doc in corpus:\n",
    "            if key in _doc:\n",
    "                docs_containing_key += 1\n",
    "        tf = value / len(lexicon)\n",
    "        if docs_containing_key:\n",
    "            idf = len(docs) / docs_containing_key\n",
    "        else:\n",
    "            idf = 0\n",
    "        vec[key] = tf*idf\n",
    "    document_tfidf_vectors.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d4adee-8290-45c5-b184-3262a3b1a947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6059d343-2151-4050-9340-bd6d5503c1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdceb767-c6ae-4ef1-a65f-d1d6cb2f06f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7440a930-e850-4665-859f-86cd4cbb5f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a0df64-98e8-4288-a743-b43758db2822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
